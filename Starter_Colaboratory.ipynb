{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "hY1gUWLzr6XR",
        "outputId": "523db40b-703b-4d99-c7cf-f40f9fcb2597"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c57a55e3-7642-4a79-8971-2ecfedfc2be0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c57a55e3-7642-4a79-8971-2ecfedfc2be0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e0711219-2359-4fd7-9916-d872f3c0c848\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0711219-2359-4fd7-9916-d872f3c0c848')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e0711219-2359-4fd7-9916-d872f3c0c848 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c57a55e3-7642-4a79-8971-2ecfedfc2be0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c57a55e3-7642-4a79-8971-2ecfedfc2be0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        EIN                          NAME APPLICATION_TYPE  AFFILIATION  \\\n",
              "0  10520599  BLUE KNIGHTS MOTORCYCLE CLUB              T10  Independent   \n",
              "\n",
              "  CLASSIFICATION    USE_CASE ORGANIZATION  STATUS INCOME_AMT  \\\n",
              "0          C1000  ProductDev  Association       1          0   \n",
              "\n",
              "  SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0                      N     5000              1  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "if not os.path.isfile('./charity_data.csv'):\n",
        "    application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "    application_df.to_csv('./charity_data.csv', encoding='utf-8')\n",
        "else:\n",
        "    application_df = pd.read_csv('./charity_data.csv')\n",
        "    application_df = application_df.loc[:, ~application_df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "application_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "WEQhKhbtsFm9",
        "outputId": "a4e0b0ad-8cdf-427d-8a70-b27ce44ec602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-6172098e-372c-4cb1-acad-c24ee9bba7bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6172098e-372c-4cb1-acad-c24ee9bba7bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4e988c25-694c-44f8-a09e-77566751de82\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e988c25-694c-44f8-a09e-77566751de82')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4e988c25-694c-44f8-a09e-77566751de82 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6172098e-372c-4cb1-acad-c24ee9bba7bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6172098e-372c-4cb1-acad-c24ee9bba7bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  APPLICATION_TYPE  AFFILIATION CLASSIFICATION    USE_CASE ORGANIZATION  \\\n",
              "0              T10  Independent          C1000  ProductDev  Association   \n",
              "\n",
              "   STATUS INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0       1          0                      N     5000              1  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df.drop(['EIN', 'NAME'],  axis=1, inplace=True)\n",
        "# application_df = application_df.loc[:, ~application_df.columns.str.contains('^Unnamed')]\n",
        "application_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM6Uez9bsF4M",
        "outputId": "be6e9b65-bde5-4e78-cbe8-652030e1dc7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiEK8DPVsF88",
        "outputId": "ce2971f7-c70c-4019-f501-d94dd6b4aabe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "application_type_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSwh_SLEs2gX",
        "outputId": "3d9ef8ca-b22e-4849-87ea-9b13ff5cb96e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T3       27037\n",
              "Other     2266\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = list(application_type_counts[application_type_counts < 750].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlF0KqTks2c2",
        "outputId": "aa0df752-d072-4413-cbba-dccef61b766d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: CLASSIFICATION, Length: 71, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_val_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "classification_val_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo421Xq3s2Ze",
        "outputId": "d4cbcfd1-83a4-442f-8549-73410dedce81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1238       10\n",
              "C1278       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C2400        6\n",
              "C1720        6\n",
              "C4100        6\n",
              "C1257        5\n",
              "C1600        5\n",
              "C1260        3\n",
              "C2710        3\n",
              "C0           3\n",
              "C3200        2\n",
              "C1234        2\n",
              "C1246        2\n",
              "C1267        2\n",
              "C1256        2\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "greater_than_one = classification_val_counts[classification_val_counts>1]\n",
        "greater_than_one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXS-SKxYs2V2",
        "outputId": "c818381d-bfdc-475f-ebdc-ce7ed2514205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Other     1484\n",
              "C7000      777\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace = list (classification_val_counts[classification_val_counts<750].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "HXbCSwNfs2SZ",
        "outputId": "52e0271f-28eb-4b82-9932-a40f047f87f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d94c186c-a650-41ec-a5ef-a3f0f8047818\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d94c186c-a650-41ec-a5ef-a3f0f8047818')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e0fdc447-d70c-4677-85f6-dbde0af6119d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0fdc447-d70c-4677-85f6-dbde0af6119d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e0fdc447-d70c-4677-85f6-dbde0af6119d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d94c186c-a650-41ec-a5ef-a3f0f8047818 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d94c186c-a650-41ec-a5ef-a3f0f8047818');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                     1.0   \n",
              "1       1   108590              1                     0.0   \n",
              "2       1     5000              0                     0.0   \n",
              "3       1     6692              1                     0.0   \n",
              "4       1   142590              1                     0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
              "0                   0.0                  0.0                  0.0   \n",
              "1                   0.0                  1.0                  0.0   \n",
              "2                   0.0                  0.0                  0.0   \n",
              "3                   0.0                  1.0                  0.0   \n",
              "4                   0.0                  1.0                  0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  AFFILIATION_CompanySponsored  \\\n",
              "0                  0.0                  0.0                           0.0   \n",
              "1                  0.0                  0.0                           0.0   \n",
              "2                  1.0                  0.0                           1.0   \n",
              "3                  0.0                  0.0                           1.0   \n",
              "4                  0.0                  0.0                           0.0   \n",
              "\n",
              "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0  ...                0.0                     0.0                       0.0   \n",
              "1  ...                1.0                     0.0                       0.0   \n",
              "2  ...                0.0                     0.0                       0.0   \n",
              "3  ...                0.0                     1.0                       0.0   \n",
              "4  ...                0.0                     0.0                       1.0   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                 0.0               0.0                     0.0   \n",
              "1                 0.0               0.0                     0.0   \n",
              "2                 0.0               0.0                     0.0   \n",
              "3                 0.0               0.0                     0.0   \n",
              "4                 0.0               0.0                     0.0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0              0.0                0.0                       1.0   \n",
              "1              0.0                0.0                       1.0   \n",
              "2              0.0                0.0                       1.0   \n",
              "3              0.0                0.0                       1.0   \n",
              "4              0.0                0.0                       1.0   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                       0.0  \n",
              "1                       0.0  \n",
              "2                       0.0  \n",
              "3                       0.0  \n",
              "4                       0.0  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_df = pd.get_dummies(application_df,dtype=float)\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwQL2NBys2Of",
        "outputId": "5ee42006-a4e9-4114-9f03-b1ad0ff53025"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-eff27e3776da>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  X = application_df.drop(['IS_SUCCESSFUL'],1).values\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.000000e+00, 2.631396e+06, 0.000000e+00, ..., 0.000000e+00,\n",
              "        1.000000e+00, 0.000000e+00],\n",
              "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
              "        1.000000e+00, 0.000000e+00],\n",
              "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
              "        1.000000e+00, 0.000000e+00],\n",
              "       ...,\n",
              "       [1.000000e+00, 1.443006e+06, 0.000000e+00, ..., 0.000000e+00,\n",
              "        1.000000e+00, 0.000000e+00],\n",
              "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
              "        1.000000e+00, 0.000000e+00],\n",
              "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
              "        1.000000e+00, 0.000000e+00]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = application_df['IS_SUCCESSFUL'].values\n",
        "X = application_df.drop(['IS_SUCCESSFUL'],1).values\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Zm3FRSAss2Kn"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgo15jMns2ER",
        "outputId": "5578b926-4b97-471e-9e69-bc9c7b9d4968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 12)                504       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 24)                312       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 841\n",
            "Trainable params: 841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "features = len( X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 12\n",
        "hidden_nodes_layer2 = 24\n",
        "# hidden_nodes_layer3 = 36 # Using this layer results worsenLoss: 0.5824776291847229, Accuracy: 0.7370262145996094\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=features, activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, input_dim=features, activation='relu'))\n",
        "\n",
        "# third hidden\n",
        "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, input_dim=features, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VMjVsx93s1xv"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psGZ2snLtHxS",
        "outputId": "c6c069e1-4ccd-43a9-940a-2459052f1567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/780\n",
            "684/684 [==============================] - 3s 3ms/step - loss: 0.6051 - accuracy: 0.6953 - val_loss: 0.5595 - val_accuracy: 0.7365\n",
            "Epoch 2/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5699 - accuracy: 0.7181 - val_loss: 0.5541 - val_accuracy: 0.7383\n",
            "Epoch 3/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.7206 - val_loss: 0.5478 - val_accuracy: 0.7388\n",
            "Epoch 4/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5623 - accuracy: 0.7234 - val_loss: 0.5475 - val_accuracy: 0.7396\n",
            "Epoch 5/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5600 - accuracy: 0.7237 - val_loss: 0.5508 - val_accuracy: 0.7406\n",
            "Epoch 6/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5594 - accuracy: 0.7255 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
            "Epoch 7/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5586 - accuracy: 0.7247 - val_loss: 0.5447 - val_accuracy: 0.7391\n",
            "Epoch 8/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5578 - accuracy: 0.7264 - val_loss: 0.5471 - val_accuracy: 0.7406\n",
            "Epoch 9/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5568 - accuracy: 0.7263 - val_loss: 0.5476 - val_accuracy: 0.7393\n",
            "Epoch 10/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5566 - accuracy: 0.7254 - val_loss: 0.5446 - val_accuracy: 0.7401\n",
            "Epoch 11/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5561 - accuracy: 0.7272 - val_loss: 0.5478 - val_accuracy: 0.7380\n",
            "Epoch 12/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5559 - accuracy: 0.7267 - val_loss: 0.5436 - val_accuracy: 0.7383\n",
            "Epoch 13/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5553 - accuracy: 0.7266 - val_loss: 0.5438 - val_accuracy: 0.7403\n",
            "Epoch 14/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5550 - accuracy: 0.7268 - val_loss: 0.5455 - val_accuracy: 0.7393\n",
            "Epoch 15/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.7276 - val_loss: 0.5458 - val_accuracy: 0.7388\n",
            "Epoch 16/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5545 - accuracy: 0.7277 - val_loss: 0.5443 - val_accuracy: 0.7388\n",
            "Epoch 17/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5542 - accuracy: 0.7275 - val_loss: 0.5459 - val_accuracy: 0.7401\n",
            "Epoch 18/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5537 - accuracy: 0.7287 - val_loss: 0.5449 - val_accuracy: 0.7409\n",
            "Epoch 19/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5537 - accuracy: 0.7286 - val_loss: 0.5432 - val_accuracy: 0.7409\n",
            "Epoch 20/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5533 - accuracy: 0.7286 - val_loss: 0.5436 - val_accuracy: 0.7401\n",
            "Epoch 21/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5530 - accuracy: 0.7289 - val_loss: 0.5484 - val_accuracy: 0.7403\n",
            "Epoch 22/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5535 - accuracy: 0.7284 - val_loss: 0.5451 - val_accuracy: 0.7388\n",
            "Epoch 23/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5530 - accuracy: 0.7283 - val_loss: 0.5456 - val_accuracy: 0.7391\n",
            "Epoch 24/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5527 - accuracy: 0.7280 - val_loss: 0.5452 - val_accuracy: 0.7385\n",
            "Epoch 25/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5523 - accuracy: 0.7288 - val_loss: 0.5499 - val_accuracy: 0.7372\n",
            "Epoch 26/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5525 - accuracy: 0.7297 - val_loss: 0.5475 - val_accuracy: 0.7393\n",
            "Epoch 27/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5525 - accuracy: 0.7301 - val_loss: 0.5463 - val_accuracy: 0.7378\n",
            "Epoch 28/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5524 - accuracy: 0.7293 - val_loss: 0.5446 - val_accuracy: 0.7406\n",
            "Epoch 29/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5518 - accuracy: 0.7297 - val_loss: 0.5466 - val_accuracy: 0.7403\n",
            "Epoch 30/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7291 - val_loss: 0.5467 - val_accuracy: 0.7375\n",
            "Epoch 31/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7286 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 32/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7291 - val_loss: 0.5447 - val_accuracy: 0.7393\n",
            "Epoch 33/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5513 - accuracy: 0.7301 - val_loss: 0.5490 - val_accuracy: 0.7349\n",
            "Epoch 34/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7293 - val_loss: 0.5458 - val_accuracy: 0.7401\n",
            "Epoch 35/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5515 - accuracy: 0.7292 - val_loss: 0.5495 - val_accuracy: 0.7383\n",
            "Epoch 36/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5513 - accuracy: 0.7296 - val_loss: 0.5453 - val_accuracy: 0.7401\n",
            "Epoch 37/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5512 - accuracy: 0.7294 - val_loss: 0.5488 - val_accuracy: 0.7388\n",
            "Epoch 38/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7299 - val_loss: 0.5469 - val_accuracy: 0.7385\n",
            "Epoch 39/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7304 - val_loss: 0.5450 - val_accuracy: 0.7367\n",
            "Epoch 40/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5511 - accuracy: 0.7304 - val_loss: 0.5458 - val_accuracy: 0.7383\n",
            "Epoch 41/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5507 - accuracy: 0.7302 - val_loss: 0.5448 - val_accuracy: 0.7391\n",
            "Epoch 42/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5502 - accuracy: 0.7301 - val_loss: 0.5489 - val_accuracy: 0.7393\n",
            "Epoch 43/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5504 - accuracy: 0.7304 - val_loss: 0.5441 - val_accuracy: 0.7367\n",
            "Epoch 44/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5508 - accuracy: 0.7299 - val_loss: 0.5438 - val_accuracy: 0.7391\n",
            "Epoch 45/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7308 - val_loss: 0.5449 - val_accuracy: 0.7401\n",
            "Epoch 46/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7308 - val_loss: 0.5509 - val_accuracy: 0.7365\n",
            "Epoch 47/780\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.5506 - accuracy: 0.7307 - val_loss: 0.5457 - val_accuracy: 0.7383\n",
            "Epoch 48/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5503 - accuracy: 0.7298 - val_loss: 0.5463 - val_accuracy: 0.7396\n",
            "Epoch 49/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7301 - val_loss: 0.5463 - val_accuracy: 0.7383\n",
            "Epoch 50/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5499 - accuracy: 0.7303 - val_loss: 0.5445 - val_accuracy: 0.7385\n",
            "Epoch 51/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5499 - accuracy: 0.7304 - val_loss: 0.5473 - val_accuracy: 0.7398\n",
            "Epoch 52/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7315 - val_loss: 0.5491 - val_accuracy: 0.7375\n",
            "Epoch 53/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5499 - accuracy: 0.7307 - val_loss: 0.5458 - val_accuracy: 0.7378\n",
            "Epoch 54/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7314 - val_loss: 0.5464 - val_accuracy: 0.7375\n",
            "Epoch 55/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5494 - accuracy: 0.7317 - val_loss: 0.5469 - val_accuracy: 0.7401\n",
            "Epoch 56/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5501 - accuracy: 0.7314 - val_loss: 0.5473 - val_accuracy: 0.7388\n",
            "Epoch 57/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5499 - accuracy: 0.7310 - val_loss: 0.5441 - val_accuracy: 0.7411\n",
            "Epoch 58/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5497 - accuracy: 0.7305 - val_loss: 0.5468 - val_accuracy: 0.7375\n",
            "Epoch 59/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7309 - val_loss: 0.5484 - val_accuracy: 0.7372\n",
            "Epoch 60/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7311 - val_loss: 0.5464 - val_accuracy: 0.7388\n",
            "Epoch 61/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7307 - val_loss: 0.5453 - val_accuracy: 0.7385\n",
            "Epoch 62/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5492 - accuracy: 0.7319 - val_loss: 0.5460 - val_accuracy: 0.7375\n",
            "Epoch 63/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5490 - accuracy: 0.7313 - val_loss: 0.5490 - val_accuracy: 0.7354\n",
            "Epoch 64/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7308 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 65/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5491 - accuracy: 0.7314 - val_loss: 0.5460 - val_accuracy: 0.7372\n",
            "Epoch 66/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5490 - accuracy: 0.7308 - val_loss: 0.5468 - val_accuracy: 0.7380\n",
            "Epoch 67/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7312 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 68/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5485 - accuracy: 0.7319 - val_loss: 0.5458 - val_accuracy: 0.7388\n",
            "Epoch 69/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7317 - val_loss: 0.5468 - val_accuracy: 0.7375\n",
            "Epoch 70/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7330 - val_loss: 0.5462 - val_accuracy: 0.7391\n",
            "Epoch 71/780\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.5482 - accuracy: 0.7330 - val_loss: 0.5498 - val_accuracy: 0.7388\n",
            "Epoch 72/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7319 - val_loss: 0.5451 - val_accuracy: 0.7372\n",
            "Epoch 73/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5485 - accuracy: 0.7305 - val_loss: 0.5487 - val_accuracy: 0.7367\n",
            "Epoch 74/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5487 - accuracy: 0.7322 - val_loss: 0.5469 - val_accuracy: 0.7391\n",
            "Epoch 75/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7320 - val_loss: 0.5465 - val_accuracy: 0.7383\n",
            "Epoch 76/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5485 - accuracy: 0.7315 - val_loss: 0.5476 - val_accuracy: 0.7383\n",
            "Epoch 77/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7320 - val_loss: 0.5463 - val_accuracy: 0.7380\n",
            "Epoch 78/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7326 - val_loss: 0.5461 - val_accuracy: 0.7378\n",
            "Epoch 79/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7321 - val_loss: 0.5459 - val_accuracy: 0.7378\n",
            "Epoch 80/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5479 - accuracy: 0.7332 - val_loss: 0.5481 - val_accuracy: 0.7378\n",
            "Epoch 81/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7321 - val_loss: 0.5475 - val_accuracy: 0.7370\n",
            "Epoch 82/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7314 - val_loss: 0.5463 - val_accuracy: 0.7393\n",
            "Epoch 83/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7321 - val_loss: 0.5482 - val_accuracy: 0.7367\n",
            "Epoch 84/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7324 - val_loss: 0.5467 - val_accuracy: 0.7372\n",
            "Epoch 85/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7334 - val_loss: 0.5482 - val_accuracy: 0.7318\n",
            "Epoch 86/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7322 - val_loss: 0.5475 - val_accuracy: 0.7365\n",
            "Epoch 87/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5478 - accuracy: 0.7311 - val_loss: 0.5461 - val_accuracy: 0.7383\n",
            "Epoch 88/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5477 - accuracy: 0.7328 - val_loss: 0.5468 - val_accuracy: 0.7385\n",
            "Epoch 89/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5478 - accuracy: 0.7319 - val_loss: 0.5483 - val_accuracy: 0.7370\n",
            "Epoch 90/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5481 - accuracy: 0.7319 - val_loss: 0.5461 - val_accuracy: 0.7375\n",
            "Epoch 91/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7324 - val_loss: 0.5490 - val_accuracy: 0.7365\n",
            "Epoch 92/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7330 - val_loss: 0.5497 - val_accuracy: 0.7365\n",
            "Epoch 93/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7324 - val_loss: 0.5498 - val_accuracy: 0.7375\n",
            "Epoch 94/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7330 - val_loss: 0.5466 - val_accuracy: 0.7367\n",
            "Epoch 95/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5474 - accuracy: 0.7318 - val_loss: 0.5489 - val_accuracy: 0.7372\n",
            "Epoch 96/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5471 - accuracy: 0.7322 - val_loss: 0.5486 - val_accuracy: 0.7383\n",
            "Epoch 97/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7332 - val_loss: 0.5489 - val_accuracy: 0.7370\n",
            "Epoch 98/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7321 - val_loss: 0.5468 - val_accuracy: 0.7362\n",
            "Epoch 99/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7325 - val_loss: 0.5477 - val_accuracy: 0.7385\n",
            "Epoch 100/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7321 - val_loss: 0.5478 - val_accuracy: 0.7372\n",
            "Epoch 101/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7328 - val_loss: 0.5465 - val_accuracy: 0.7380\n",
            "Epoch 102/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5469 - accuracy: 0.7330 - val_loss: 0.5477 - val_accuracy: 0.7370\n",
            "Epoch 103/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5470 - accuracy: 0.7330 - val_loss: 0.5497 - val_accuracy: 0.7375\n",
            "Epoch 104/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7323 - val_loss: 0.5458 - val_accuracy: 0.7365\n",
            "Epoch 105/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7328 - val_loss: 0.5493 - val_accuracy: 0.7375\n",
            "Epoch 106/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7326 - val_loss: 0.5483 - val_accuracy: 0.7372\n",
            "Epoch 107/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7328 - val_loss: 0.5448 - val_accuracy: 0.7385\n",
            "Epoch 108/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7335 - val_loss: 0.5465 - val_accuracy: 0.7383\n",
            "Epoch 109/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7331 - val_loss: 0.5497 - val_accuracy: 0.7372\n",
            "Epoch 110/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5466 - accuracy: 0.7327 - val_loss: 0.5473 - val_accuracy: 0.7365\n",
            "Epoch 111/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5470 - accuracy: 0.7329 - val_loss: 0.5458 - val_accuracy: 0.7385\n",
            "Epoch 112/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7330 - val_loss: 0.5493 - val_accuracy: 0.7375\n",
            "Epoch 113/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7322 - val_loss: 0.5493 - val_accuracy: 0.7372\n",
            "Epoch 114/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5471 - accuracy: 0.7330 - val_loss: 0.5470 - val_accuracy: 0.7372\n",
            "Epoch 115/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7325 - val_loss: 0.5481 - val_accuracy: 0.7380\n",
            "Epoch 116/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7326 - val_loss: 0.5494 - val_accuracy: 0.7385\n",
            "Epoch 117/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7330 - val_loss: 0.5496 - val_accuracy: 0.7344\n",
            "Epoch 118/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5465 - accuracy: 0.7327 - val_loss: 0.5489 - val_accuracy: 0.7370\n",
            "Epoch 119/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5465 - accuracy: 0.7334 - val_loss: 0.5496 - val_accuracy: 0.7352\n",
            "Epoch 120/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7329 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
            "Epoch 121/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7338 - val_loss: 0.5482 - val_accuracy: 0.7370\n",
            "Epoch 122/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5463 - accuracy: 0.7323 - val_loss: 0.5476 - val_accuracy: 0.7372\n",
            "Epoch 123/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7327 - val_loss: 0.5474 - val_accuracy: 0.7378\n",
            "Epoch 124/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7331 - val_loss: 0.5485 - val_accuracy: 0.7383\n",
            "Epoch 125/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5465 - accuracy: 0.7338 - val_loss: 0.5474 - val_accuracy: 0.7388\n",
            "Epoch 126/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5463 - accuracy: 0.7341 - val_loss: 0.5472 - val_accuracy: 0.7383\n",
            "Epoch 127/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7341 - val_loss: 0.5489 - val_accuracy: 0.7370\n",
            "Epoch 128/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7337 - val_loss: 0.5477 - val_accuracy: 0.7370\n",
            "Epoch 129/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7335 - val_loss: 0.5477 - val_accuracy: 0.7375\n",
            "Epoch 130/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7330 - val_loss: 0.5486 - val_accuracy: 0.7383\n",
            "Epoch 131/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7330 - val_loss: 0.5484 - val_accuracy: 0.7375\n",
            "Epoch 132/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7333 - val_loss: 0.5467 - val_accuracy: 0.7378\n",
            "Epoch 133/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5462 - accuracy: 0.7329 - val_loss: 0.5486 - val_accuracy: 0.7354\n",
            "Epoch 134/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7342 - val_loss: 0.5536 - val_accuracy: 0.7359\n",
            "Epoch 135/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7328 - val_loss: 0.5481 - val_accuracy: 0.7380\n",
            "Epoch 136/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7334 - val_loss: 0.5517 - val_accuracy: 0.7328\n",
            "Epoch 137/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7334 - val_loss: 0.5501 - val_accuracy: 0.7339\n",
            "Epoch 138/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7332 - val_loss: 0.5485 - val_accuracy: 0.7362\n",
            "Epoch 139/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7324 - val_loss: 0.5510 - val_accuracy: 0.7365\n",
            "Epoch 140/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5458 - accuracy: 0.7329 - val_loss: 0.5474 - val_accuracy: 0.7372\n",
            "Epoch 141/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5458 - accuracy: 0.7333 - val_loss: 0.5514 - val_accuracy: 0.7315\n",
            "Epoch 142/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5456 - accuracy: 0.7334 - val_loss: 0.5499 - val_accuracy: 0.7352\n",
            "Epoch 143/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7333 - val_loss: 0.5508 - val_accuracy: 0.7336\n",
            "Epoch 144/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7341 - val_loss: 0.5491 - val_accuracy: 0.7357\n",
            "Epoch 145/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7330 - val_loss: 0.5476 - val_accuracy: 0.7380\n",
            "Epoch 146/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7337 - val_loss: 0.5491 - val_accuracy: 0.7367\n",
            "Epoch 147/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7332 - val_loss: 0.5511 - val_accuracy: 0.7370\n",
            "Epoch 148/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5458 - accuracy: 0.7335 - val_loss: 0.5487 - val_accuracy: 0.7359\n",
            "Epoch 149/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5457 - accuracy: 0.7337 - val_loss: 0.5485 - val_accuracy: 0.7346\n",
            "Epoch 150/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7330 - val_loss: 0.5497 - val_accuracy: 0.7362\n",
            "Epoch 151/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7341 - val_loss: 0.5502 - val_accuracy: 0.7357\n",
            "Epoch 152/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7342 - val_loss: 0.5520 - val_accuracy: 0.7362\n",
            "Epoch 153/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7334 - val_loss: 0.5509 - val_accuracy: 0.7367\n",
            "Epoch 154/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7344 - val_loss: 0.5503 - val_accuracy: 0.7354\n",
            "Epoch 155/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5460 - accuracy: 0.7326 - val_loss: 0.5478 - val_accuracy: 0.7370\n",
            "Epoch 156/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5455 - accuracy: 0.7332 - val_loss: 0.5502 - val_accuracy: 0.7372\n",
            "Epoch 157/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5457 - accuracy: 0.7338 - val_loss: 0.5475 - val_accuracy: 0.7383\n",
            "Epoch 158/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7336 - val_loss: 0.5491 - val_accuracy: 0.7357\n",
            "Epoch 159/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7343 - val_loss: 0.5474 - val_accuracy: 0.7365\n",
            "Epoch 160/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7336 - val_loss: 0.5491 - val_accuracy: 0.7352\n",
            "Epoch 161/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7332 - val_loss: 0.5496 - val_accuracy: 0.7357\n",
            "Epoch 162/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7340 - val_loss: 0.5466 - val_accuracy: 0.7378\n",
            "Epoch 163/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7330 - val_loss: 0.5480 - val_accuracy: 0.7359\n",
            "Epoch 164/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5454 - accuracy: 0.7338 - val_loss: 0.5496 - val_accuracy: 0.7349\n",
            "Epoch 165/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7334 - val_loss: 0.5491 - val_accuracy: 0.7362\n",
            "Epoch 166/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5456 - accuracy: 0.7335 - val_loss: 0.5493 - val_accuracy: 0.7362\n",
            "Epoch 167/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7334 - val_loss: 0.5501 - val_accuracy: 0.7370\n",
            "Epoch 168/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7345 - val_loss: 0.5525 - val_accuracy: 0.7341\n",
            "Epoch 169/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7339 - val_loss: 0.5513 - val_accuracy: 0.7341\n",
            "Epoch 170/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5457 - accuracy: 0.7337 - val_loss: 0.5499 - val_accuracy: 0.7362\n",
            "Epoch 171/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7338 - val_loss: 0.5484 - val_accuracy: 0.7372\n",
            "Epoch 172/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5456 - accuracy: 0.7330 - val_loss: 0.5501 - val_accuracy: 0.7367\n",
            "Epoch 173/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7342 - val_loss: 0.5490 - val_accuracy: 0.7362\n",
            "Epoch 174/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7340 - val_loss: 0.5506 - val_accuracy: 0.7359\n",
            "Epoch 175/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7330 - val_loss: 0.5489 - val_accuracy: 0.7370\n",
            "Epoch 176/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5451 - accuracy: 0.7328 - val_loss: 0.5526 - val_accuracy: 0.7354\n",
            "Epoch 177/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7342 - val_loss: 0.5488 - val_accuracy: 0.7370\n",
            "Epoch 178/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7339 - val_loss: 0.5494 - val_accuracy: 0.7370\n",
            "Epoch 179/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5454 - accuracy: 0.7345 - val_loss: 0.5515 - val_accuracy: 0.7362\n",
            "Epoch 180/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7334 - val_loss: 0.5498 - val_accuracy: 0.7365\n",
            "Epoch 181/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7335 - val_loss: 0.5504 - val_accuracy: 0.7326\n",
            "Epoch 182/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7332 - val_loss: 0.5481 - val_accuracy: 0.7375\n",
            "Epoch 183/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5455 - accuracy: 0.7331 - val_loss: 0.5484 - val_accuracy: 0.7378\n",
            "Epoch 184/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7341 - val_loss: 0.5484 - val_accuracy: 0.7372\n",
            "Epoch 185/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7340 - val_loss: 0.5516 - val_accuracy: 0.7365\n",
            "Epoch 186/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7344 - val_loss: 0.5483 - val_accuracy: 0.7370\n",
            "Epoch 187/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7335 - val_loss: 0.5551 - val_accuracy: 0.7349\n",
            "Epoch 188/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7331 - val_loss: 0.5530 - val_accuracy: 0.7357\n",
            "Epoch 189/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7334 - val_loss: 0.5474 - val_accuracy: 0.7380\n",
            "Epoch 190/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5455 - accuracy: 0.7330 - val_loss: 0.5511 - val_accuracy: 0.7372\n",
            "Epoch 191/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7339 - val_loss: 0.5481 - val_accuracy: 0.7375\n",
            "Epoch 192/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7336 - val_loss: 0.5486 - val_accuracy: 0.7365\n",
            "Epoch 193/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7338 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 194/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7334 - val_loss: 0.5484 - val_accuracy: 0.7385\n",
            "Epoch 195/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7347 - val_loss: 0.5498 - val_accuracy: 0.7367\n",
            "Epoch 196/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7330 - val_loss: 0.5505 - val_accuracy: 0.7359\n",
            "Epoch 197/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7342 - val_loss: 0.5501 - val_accuracy: 0.7370\n",
            "Epoch 198/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7340 - val_loss: 0.5496 - val_accuracy: 0.7383\n",
            "Epoch 199/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7347 - val_loss: 0.5500 - val_accuracy: 0.7346\n",
            "Epoch 200/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7334 - val_loss: 0.5505 - val_accuracy: 0.7367\n",
            "Epoch 201/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7345 - val_loss: 0.5530 - val_accuracy: 0.7305\n",
            "Epoch 202/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7343 - val_loss: 0.5508 - val_accuracy: 0.7372\n",
            "Epoch 203/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7344 - val_loss: 0.5496 - val_accuracy: 0.7359\n",
            "Epoch 204/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7342 - val_loss: 0.5475 - val_accuracy: 0.7362\n",
            "Epoch 205/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5451 - accuracy: 0.7337 - val_loss: 0.5493 - val_accuracy: 0.7359\n",
            "Epoch 206/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7343 - val_loss: 0.5464 - val_accuracy: 0.7378\n",
            "Epoch 207/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5447 - accuracy: 0.7331 - val_loss: 0.5500 - val_accuracy: 0.7370\n",
            "Epoch 208/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7345 - val_loss: 0.5519 - val_accuracy: 0.7336\n",
            "Epoch 209/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7344 - val_loss: 0.5492 - val_accuracy: 0.7365\n",
            "Epoch 210/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7341 - val_loss: 0.5528 - val_accuracy: 0.7367\n",
            "Epoch 211/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7349 - val_loss: 0.5511 - val_accuracy: 0.7359\n",
            "Epoch 212/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7339 - val_loss: 0.5495 - val_accuracy: 0.7367\n",
            "Epoch 213/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7348 - val_loss: 0.5542 - val_accuracy: 0.7372\n",
            "Epoch 214/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7334 - val_loss: 0.5513 - val_accuracy: 0.7359\n",
            "Epoch 215/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7346 - val_loss: 0.5505 - val_accuracy: 0.7367\n",
            "Epoch 216/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7333 - val_loss: 0.5507 - val_accuracy: 0.7380\n",
            "Epoch 217/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7348 - val_loss: 0.5506 - val_accuracy: 0.7370\n",
            "Epoch 218/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7340 - val_loss: 0.5511 - val_accuracy: 0.7362\n",
            "Epoch 219/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7340 - val_loss: 0.5517 - val_accuracy: 0.7354\n",
            "Epoch 220/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7335 - val_loss: 0.5496 - val_accuracy: 0.7349\n",
            "Epoch 221/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7331 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
            "Epoch 222/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7330 - val_loss: 0.5496 - val_accuracy: 0.7370\n",
            "Epoch 223/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7346 - val_loss: 0.5485 - val_accuracy: 0.7372\n",
            "Epoch 224/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7339 - val_loss: 0.5505 - val_accuracy: 0.7354\n",
            "Epoch 225/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7347 - val_loss: 0.5525 - val_accuracy: 0.7357\n",
            "Epoch 226/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7328 - val_loss: 0.5496 - val_accuracy: 0.7362\n",
            "Epoch 227/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7350 - val_loss: 0.5489 - val_accuracy: 0.7375\n",
            "Epoch 228/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7342 - val_loss: 0.5504 - val_accuracy: 0.7354\n",
            "Epoch 229/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7345 - val_loss: 0.5485 - val_accuracy: 0.7367\n",
            "Epoch 230/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7349 - val_loss: 0.5491 - val_accuracy: 0.7378\n",
            "Epoch 231/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7338 - val_loss: 0.5515 - val_accuracy: 0.7370\n",
            "Epoch 232/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7353 - val_loss: 0.5484 - val_accuracy: 0.7378\n",
            "Epoch 233/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7336 - val_loss: 0.5489 - val_accuracy: 0.7354\n",
            "Epoch 234/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7341 - val_loss: 0.5508 - val_accuracy: 0.7359\n",
            "Epoch 235/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7336 - val_loss: 0.5487 - val_accuracy: 0.7367\n",
            "Epoch 236/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7330 - val_loss: 0.5490 - val_accuracy: 0.7367\n",
            "Epoch 237/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7346 - val_loss: 0.5516 - val_accuracy: 0.7367\n",
            "Epoch 238/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7340 - val_loss: 0.5480 - val_accuracy: 0.7383\n",
            "Epoch 239/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7341 - val_loss: 0.5522 - val_accuracy: 0.7362\n",
            "Epoch 240/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7338 - val_loss: 0.5486 - val_accuracy: 0.7370\n",
            "Epoch 241/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7338 - val_loss: 0.5482 - val_accuracy: 0.7372\n",
            "Epoch 242/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7344 - val_loss: 0.5499 - val_accuracy: 0.7370\n",
            "Epoch 243/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7346 - val_loss: 0.5509 - val_accuracy: 0.7346\n",
            "Epoch 244/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7345 - val_loss: 0.5509 - val_accuracy: 0.7365\n",
            "Epoch 245/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7336 - val_loss: 0.5494 - val_accuracy: 0.7359\n",
            "Epoch 246/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7340 - val_loss: 0.5494 - val_accuracy: 0.7380\n",
            "Epoch 247/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7346 - val_loss: 0.5522 - val_accuracy: 0.7372\n",
            "Epoch 248/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7351 - val_loss: 0.5486 - val_accuracy: 0.7367\n",
            "Epoch 249/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7343 - val_loss: 0.5511 - val_accuracy: 0.7370\n",
            "Epoch 250/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7340 - val_loss: 0.5502 - val_accuracy: 0.7375\n",
            "Epoch 251/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7351 - val_loss: 0.5474 - val_accuracy: 0.7362\n",
            "Epoch 252/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7334 - val_loss: 0.5499 - val_accuracy: 0.7370\n",
            "Epoch 253/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7340 - val_loss: 0.5479 - val_accuracy: 0.7367\n",
            "Epoch 254/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7342 - val_loss: 0.5518 - val_accuracy: 0.7375\n",
            "Epoch 255/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7348 - val_loss: 0.5501 - val_accuracy: 0.7380\n",
            "Epoch 256/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7351 - val_loss: 0.5489 - val_accuracy: 0.7375\n",
            "Epoch 257/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7342 - val_loss: 0.5504 - val_accuracy: 0.7370\n",
            "Epoch 258/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7343 - val_loss: 0.5492 - val_accuracy: 0.7354\n",
            "Epoch 259/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7348 - val_loss: 0.5471 - val_accuracy: 0.7362\n",
            "Epoch 260/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7341 - val_loss: 0.5508 - val_accuracy: 0.7380\n",
            "Epoch 261/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7346 - val_loss: 0.5501 - val_accuracy: 0.7367\n",
            "Epoch 262/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7339 - val_loss: 0.5500 - val_accuracy: 0.7357\n",
            "Epoch 263/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7346 - val_loss: 0.5506 - val_accuracy: 0.7357\n",
            "Epoch 264/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7337 - val_loss: 0.5499 - val_accuracy: 0.7362\n",
            "Epoch 265/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7347 - val_loss: 0.5516 - val_accuracy: 0.7362\n",
            "Epoch 266/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7342 - val_loss: 0.5501 - val_accuracy: 0.7365\n",
            "Epoch 267/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5519 - val_accuracy: 0.7354\n",
            "Epoch 268/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7340 - val_loss: 0.5505 - val_accuracy: 0.7357\n",
            "Epoch 269/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7343 - val_loss: 0.5491 - val_accuracy: 0.7357\n",
            "Epoch 270/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7356 - val_loss: 0.5517 - val_accuracy: 0.7365\n",
            "Epoch 271/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7341 - val_loss: 0.5539 - val_accuracy: 0.7367\n",
            "Epoch 272/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7344 - val_loss: 0.5494 - val_accuracy: 0.7378\n",
            "Epoch 273/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7336 - val_loss: 0.5526 - val_accuracy: 0.7370\n",
            "Epoch 274/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7343 - val_loss: 0.5507 - val_accuracy: 0.7365\n",
            "Epoch 275/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7345 - val_loss: 0.5493 - val_accuracy: 0.7362\n",
            "Epoch 276/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7343 - val_loss: 0.5497 - val_accuracy: 0.7380\n",
            "Epoch 277/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7342 - val_loss: 0.5512 - val_accuracy: 0.7357\n",
            "Epoch 278/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7349 - val_loss: 0.5538 - val_accuracy: 0.7339\n",
            "Epoch 279/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7338 - val_loss: 0.5490 - val_accuracy: 0.7367\n",
            "Epoch 280/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7349 - val_loss: 0.5492 - val_accuracy: 0.7372\n",
            "Epoch 281/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7346 - val_loss: 0.5492 - val_accuracy: 0.7375\n",
            "Epoch 282/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7347 - val_loss: 0.5503 - val_accuracy: 0.7378\n",
            "Epoch 283/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7343 - val_loss: 0.5529 - val_accuracy: 0.7341\n",
            "Epoch 284/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7347 - val_loss: 0.5520 - val_accuracy: 0.7352\n",
            "Epoch 285/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7345 - val_loss: 0.5495 - val_accuracy: 0.7365\n",
            "Epoch 286/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7338 - val_loss: 0.5519 - val_accuracy: 0.7378\n",
            "Epoch 287/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7343 - val_loss: 0.5496 - val_accuracy: 0.7380\n",
            "Epoch 288/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7348 - val_loss: 0.5486 - val_accuracy: 0.7385\n",
            "Epoch 289/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7347 - val_loss: 0.5505 - val_accuracy: 0.7367\n",
            "Epoch 290/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7334 - val_loss: 0.5508 - val_accuracy: 0.7378\n",
            "Epoch 291/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7338 - val_loss: 0.5504 - val_accuracy: 0.7370\n",
            "Epoch 292/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7342 - val_loss: 0.5508 - val_accuracy: 0.7336\n",
            "Epoch 293/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7353 - val_loss: 0.5515 - val_accuracy: 0.7370\n",
            "Epoch 294/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7341 - val_loss: 0.5505 - val_accuracy: 0.7380\n",
            "Epoch 295/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7339 - val_loss: 0.5489 - val_accuracy: 0.7370\n",
            "Epoch 296/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7341 - val_loss: 0.5498 - val_accuracy: 0.7365\n",
            "Epoch 297/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5496 - val_accuracy: 0.7378\n",
            "Epoch 298/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5513 - val_accuracy: 0.7357\n",
            "Epoch 299/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5510 - val_accuracy: 0.7385\n",
            "Epoch 300/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7344 - val_loss: 0.5514 - val_accuracy: 0.7372\n",
            "Epoch 301/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7349 - val_loss: 0.5493 - val_accuracy: 0.7367\n",
            "Epoch 302/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7354 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 303/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7340 - val_loss: 0.5505 - val_accuracy: 0.7375\n",
            "Epoch 304/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7347 - val_loss: 0.5515 - val_accuracy: 0.7385\n",
            "Epoch 305/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7351 - val_loss: 0.5579 - val_accuracy: 0.7346\n",
            "Epoch 306/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7335 - val_loss: 0.5504 - val_accuracy: 0.7367\n",
            "Epoch 307/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7342 - val_loss: 0.5504 - val_accuracy: 0.7372\n",
            "Epoch 308/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7351 - val_loss: 0.5503 - val_accuracy: 0.7367\n",
            "Epoch 309/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7345 - val_loss: 0.5508 - val_accuracy: 0.7372\n",
            "Epoch 310/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7344 - val_loss: 0.5532 - val_accuracy: 0.7380\n",
            "Epoch 311/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7351 - val_loss: 0.5532 - val_accuracy: 0.7375\n",
            "Epoch 312/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7349 - val_loss: 0.5510 - val_accuracy: 0.7370\n",
            "Epoch 313/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7346 - val_loss: 0.5533 - val_accuracy: 0.7359\n",
            "Epoch 314/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7337 - val_loss: 0.5510 - val_accuracy: 0.7365\n",
            "Epoch 315/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7345 - val_loss: 0.5536 - val_accuracy: 0.7359\n",
            "Epoch 316/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7346 - val_loss: 0.5502 - val_accuracy: 0.7375\n",
            "Epoch 317/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7344 - val_loss: 0.5520 - val_accuracy: 0.7349\n",
            "Epoch 318/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7339 - val_loss: 0.5504 - val_accuracy: 0.7375\n",
            "Epoch 319/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7353 - val_loss: 0.5509 - val_accuracy: 0.7354\n",
            "Epoch 320/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7341 - val_loss: 0.5525 - val_accuracy: 0.7372\n",
            "Epoch 321/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7347 - val_loss: 0.5538 - val_accuracy: 0.7380\n",
            "Epoch 322/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7343 - val_loss: 0.5505 - val_accuracy: 0.7380\n",
            "Epoch 323/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7337 - val_loss: 0.5516 - val_accuracy: 0.7372\n",
            "Epoch 324/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7351 - val_loss: 0.5509 - val_accuracy: 0.7375\n",
            "Epoch 325/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7349 - val_loss: 0.5486 - val_accuracy: 0.7372\n",
            "Epoch 326/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7338 - val_loss: 0.5514 - val_accuracy: 0.7370\n",
            "Epoch 327/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7346 - val_loss: 0.5519 - val_accuracy: 0.7367\n",
            "Epoch 328/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7352 - val_loss: 0.5540 - val_accuracy: 0.7352\n",
            "Epoch 329/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7345 - val_loss: 0.5505 - val_accuracy: 0.7370\n",
            "Epoch 330/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7349 - val_loss: 0.5522 - val_accuracy: 0.7367\n",
            "Epoch 331/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7351 - val_loss: 0.5481 - val_accuracy: 0.7375\n",
            "Epoch 332/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7338 - val_loss: 0.5508 - val_accuracy: 0.7370\n",
            "Epoch 333/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7348 - val_loss: 0.5484 - val_accuracy: 0.7362\n",
            "Epoch 334/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7351 - val_loss: 0.5493 - val_accuracy: 0.7370\n",
            "Epoch 335/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7346 - val_loss: 0.5501 - val_accuracy: 0.7383\n",
            "Epoch 336/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7346 - val_loss: 0.5505 - val_accuracy: 0.7362\n",
            "Epoch 337/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5555 - val_accuracy: 0.7352\n",
            "Epoch 338/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7350 - val_loss: 0.5535 - val_accuracy: 0.7372\n",
            "Epoch 339/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7348 - val_loss: 0.5525 - val_accuracy: 0.7380\n",
            "Epoch 340/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7339 - val_loss: 0.5514 - val_accuracy: 0.7375\n",
            "Epoch 341/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7349 - val_loss: 0.5504 - val_accuracy: 0.7367\n",
            "Epoch 342/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7347 - val_loss: 0.5544 - val_accuracy: 0.7375\n",
            "Epoch 343/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7351 - val_loss: 0.5522 - val_accuracy: 0.7354\n",
            "Epoch 344/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5499 - val_accuracy: 0.7378\n",
            "Epoch 345/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7338 - val_loss: 0.5490 - val_accuracy: 0.7380\n",
            "Epoch 346/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7355 - val_loss: 0.5535 - val_accuracy: 0.7375\n",
            "Epoch 347/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5528 - val_accuracy: 0.7357\n",
            "Epoch 348/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7347 - val_loss: 0.5515 - val_accuracy: 0.7378\n",
            "Epoch 349/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7348 - val_loss: 0.5505 - val_accuracy: 0.7378\n",
            "Epoch 350/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7338 - val_loss: 0.5527 - val_accuracy: 0.7354\n",
            "Epoch 351/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7340 - val_loss: 0.5509 - val_accuracy: 0.7352\n",
            "Epoch 352/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7344 - val_loss: 0.5526 - val_accuracy: 0.7367\n",
            "Epoch 353/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7344 - val_loss: 0.5527 - val_accuracy: 0.7372\n",
            "Epoch 354/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7357 - val_loss: 0.5514 - val_accuracy: 0.7388\n",
            "Epoch 355/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7341 - val_loss: 0.5524 - val_accuracy: 0.7365\n",
            "Epoch 356/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7345 - val_loss: 0.5536 - val_accuracy: 0.7370\n",
            "Epoch 357/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7350 - val_loss: 0.5519 - val_accuracy: 0.7362\n",
            "Epoch 358/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7346 - val_loss: 0.5532 - val_accuracy: 0.7334\n",
            "Epoch 359/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7341 - val_loss: 0.5535 - val_accuracy: 0.7367\n",
            "Epoch 360/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7352 - val_loss: 0.5516 - val_accuracy: 0.7352\n",
            "Epoch 361/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7346 - val_loss: 0.5528 - val_accuracy: 0.7380\n",
            "Epoch 362/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7353 - val_loss: 0.5530 - val_accuracy: 0.7367\n",
            "Epoch 363/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7346 - val_loss: 0.5531 - val_accuracy: 0.7367\n",
            "Epoch 364/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7353 - val_loss: 0.5512 - val_accuracy: 0.7362\n",
            "Epoch 365/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7344 - val_loss: 0.5519 - val_accuracy: 0.7393\n",
            "Epoch 366/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7349 - val_loss: 0.5512 - val_accuracy: 0.7367\n",
            "Epoch 367/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7345 - val_loss: 0.5509 - val_accuracy: 0.7370\n",
            "Epoch 368/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7349 - val_loss: 0.5507 - val_accuracy: 0.7372\n",
            "Epoch 369/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7352 - val_loss: 0.5512 - val_accuracy: 0.7367\n",
            "Epoch 370/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7354 - val_loss: 0.5545 - val_accuracy: 0.7349\n",
            "Epoch 371/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7352 - val_loss: 0.5503 - val_accuracy: 0.7346\n",
            "Epoch 372/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7345 - val_loss: 0.5514 - val_accuracy: 0.7365\n",
            "Epoch 373/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7342 - val_loss: 0.5516 - val_accuracy: 0.7349\n",
            "Epoch 374/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7348 - val_loss: 0.5510 - val_accuracy: 0.7375\n",
            "Epoch 375/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5503 - val_accuracy: 0.7378\n",
            "Epoch 376/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7338 - val_loss: 0.5495 - val_accuracy: 0.7383\n",
            "Epoch 377/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7343 - val_loss: 0.5516 - val_accuracy: 0.7375\n",
            "Epoch 378/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7345 - val_loss: 0.5518 - val_accuracy: 0.7388\n",
            "Epoch 379/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7348 - val_loss: 0.5548 - val_accuracy: 0.7354\n",
            "Epoch 380/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7349 - val_loss: 0.5518 - val_accuracy: 0.7375\n",
            "Epoch 381/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7341 - val_loss: 0.5513 - val_accuracy: 0.7372\n",
            "Epoch 382/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7346 - val_loss: 0.5554 - val_accuracy: 0.7354\n",
            "Epoch 383/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7351 - val_loss: 0.5505 - val_accuracy: 0.7375\n",
            "Epoch 384/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7347 - val_loss: 0.5502 - val_accuracy: 0.7383\n",
            "Epoch 385/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7346 - val_loss: 0.5527 - val_accuracy: 0.7365\n",
            "Epoch 386/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7336 - val_loss: 0.5502 - val_accuracy: 0.7380\n",
            "Epoch 387/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7347 - val_loss: 0.5491 - val_accuracy: 0.7370\n",
            "Epoch 388/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7353 - val_loss: 0.5523 - val_accuracy: 0.7370\n",
            "Epoch 389/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7347 - val_loss: 0.5503 - val_accuracy: 0.7352\n",
            "Epoch 390/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7346 - val_loss: 0.5523 - val_accuracy: 0.7372\n",
            "Epoch 391/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5511 - val_accuracy: 0.7362\n",
            "Epoch 392/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7341 - val_loss: 0.5528 - val_accuracy: 0.7365\n",
            "Epoch 393/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7346 - val_loss: 0.5500 - val_accuracy: 0.7367\n",
            "Epoch 394/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7347 - val_loss: 0.5534 - val_accuracy: 0.7354\n",
            "Epoch 395/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7337 - val_loss: 0.5525 - val_accuracy: 0.7370\n",
            "Epoch 396/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7353 - val_loss: 0.5540 - val_accuracy: 0.7357\n",
            "Epoch 397/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7350 - val_loss: 0.5512 - val_accuracy: 0.7365\n",
            "Epoch 398/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7350 - val_loss: 0.5525 - val_accuracy: 0.7370\n",
            "Epoch 399/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7342 - val_loss: 0.5532 - val_accuracy: 0.7365\n",
            "Epoch 400/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7338 - val_loss: 0.5530 - val_accuracy: 0.7370\n",
            "Epoch 401/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7345 - val_loss: 0.5523 - val_accuracy: 0.7354\n",
            "Epoch 402/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7343 - val_loss: 0.5529 - val_accuracy: 0.7380\n",
            "Epoch 403/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7347 - val_loss: 0.5535 - val_accuracy: 0.7375\n",
            "Epoch 404/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7347 - val_loss: 0.5525 - val_accuracy: 0.7359\n",
            "Epoch 405/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7346 - val_loss: 0.5537 - val_accuracy: 0.7357\n",
            "Epoch 406/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7352 - val_loss: 0.5501 - val_accuracy: 0.7367\n",
            "Epoch 407/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7344 - val_loss: 0.5517 - val_accuracy: 0.7357\n",
            "Epoch 408/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7349 - val_loss: 0.5508 - val_accuracy: 0.7375\n",
            "Epoch 409/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7348 - val_loss: 0.5520 - val_accuracy: 0.7346\n",
            "Epoch 410/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7347 - val_loss: 0.5525 - val_accuracy: 0.7352\n",
            "Epoch 411/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7346 - val_loss: 0.5533 - val_accuracy: 0.7334\n",
            "Epoch 412/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7350 - val_loss: 0.5512 - val_accuracy: 0.7367\n",
            "Epoch 413/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7357 - val_loss: 0.5507 - val_accuracy: 0.7378\n",
            "Epoch 414/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7343 - val_loss: 0.5506 - val_accuracy: 0.7362\n",
            "Epoch 415/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7340 - val_loss: 0.5529 - val_accuracy: 0.7372\n",
            "Epoch 416/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5536 - val_accuracy: 0.7383\n",
            "Epoch 417/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7345 - val_loss: 0.5511 - val_accuracy: 0.7372\n",
            "Epoch 418/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7341 - val_loss: 0.5514 - val_accuracy: 0.7370\n",
            "Epoch 419/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7359 - val_loss: 0.5503 - val_accuracy: 0.7362\n",
            "Epoch 420/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7340 - val_loss: 0.5528 - val_accuracy: 0.7359\n",
            "Epoch 421/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7348 - val_loss: 0.5526 - val_accuracy: 0.7352\n",
            "Epoch 422/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7340 - val_loss: 0.5504 - val_accuracy: 0.7391\n",
            "Epoch 423/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7349 - val_loss: 0.5535 - val_accuracy: 0.7357\n",
            "Epoch 424/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7346 - val_loss: 0.5545 - val_accuracy: 0.7359\n",
            "Epoch 425/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7349 - val_loss: 0.5548 - val_accuracy: 0.7354\n",
            "Epoch 426/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7351 - val_loss: 0.5515 - val_accuracy: 0.7362\n",
            "Epoch 427/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7351 - val_loss: 0.5501 - val_accuracy: 0.7367\n",
            "Epoch 428/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7351 - val_loss: 0.5522 - val_accuracy: 0.7365\n",
            "Epoch 429/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7343 - val_loss: 0.5561 - val_accuracy: 0.7367\n",
            "Epoch 430/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7346 - val_loss: 0.5509 - val_accuracy: 0.7370\n",
            "Epoch 431/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7347 - val_loss: 0.5503 - val_accuracy: 0.7372\n",
            "Epoch 432/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7343 - val_loss: 0.5540 - val_accuracy: 0.7362\n",
            "Epoch 433/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7351 - val_loss: 0.5513 - val_accuracy: 0.7375\n",
            "Epoch 434/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7353 - val_loss: 0.5511 - val_accuracy: 0.7375\n",
            "Epoch 435/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7355 - val_loss: 0.5529 - val_accuracy: 0.7365\n",
            "Epoch 436/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7349 - val_loss: 0.5510 - val_accuracy: 0.7375\n",
            "Epoch 437/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7341 - val_loss: 0.5537 - val_accuracy: 0.7380\n",
            "Epoch 438/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7343 - val_loss: 0.5517 - val_accuracy: 0.7367\n",
            "Epoch 439/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7343 - val_loss: 0.5506 - val_accuracy: 0.7365\n",
            "Epoch 440/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5551 - val_accuracy: 0.7370\n",
            "Epoch 441/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7359 - val_loss: 0.5537 - val_accuracy: 0.7362\n",
            "Epoch 442/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5539 - val_accuracy: 0.7370\n",
            "Epoch 443/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7345 - val_loss: 0.5540 - val_accuracy: 0.7372\n",
            "Epoch 444/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7348 - val_loss: 0.5533 - val_accuracy: 0.7365\n",
            "Epoch 445/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7359 - val_loss: 0.5505 - val_accuracy: 0.7375\n",
            "Epoch 446/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7358 - val_loss: 0.5536 - val_accuracy: 0.7339\n",
            "Epoch 447/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5537 - val_accuracy: 0.7359\n",
            "Epoch 448/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7352 - val_loss: 0.5564 - val_accuracy: 0.7354\n",
            "Epoch 449/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7354 - val_loss: 0.5540 - val_accuracy: 0.7383\n",
            "Epoch 450/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5554 - val_accuracy: 0.7349\n",
            "Epoch 451/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7352 - val_loss: 0.5541 - val_accuracy: 0.7354\n",
            "Epoch 452/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7350 - val_loss: 0.5575 - val_accuracy: 0.7367\n",
            "Epoch 453/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7356 - val_loss: 0.5511 - val_accuracy: 0.7372\n",
            "Epoch 454/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7346 - val_loss: 0.5516 - val_accuracy: 0.7380\n",
            "Epoch 455/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7346 - val_loss: 0.5524 - val_accuracy: 0.7354\n",
            "Epoch 456/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7352 - val_loss: 0.5530 - val_accuracy: 0.7375\n",
            "Epoch 457/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5562 - val_accuracy: 0.7357\n",
            "Epoch 458/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7350 - val_loss: 0.5546 - val_accuracy: 0.7378\n",
            "Epoch 459/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7353 - val_loss: 0.5517 - val_accuracy: 0.7370\n",
            "Epoch 460/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7340 - val_loss: 0.5491 - val_accuracy: 0.7372\n",
            "Epoch 461/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7346 - val_loss: 0.5533 - val_accuracy: 0.7380\n",
            "Epoch 462/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7357 - val_loss: 0.5527 - val_accuracy: 0.7383\n",
            "Epoch 463/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7346 - val_loss: 0.5515 - val_accuracy: 0.7365\n",
            "Epoch 464/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7348 - val_loss: 0.5558 - val_accuracy: 0.7365\n",
            "Epoch 465/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5508 - val_accuracy: 0.7383\n",
            "Epoch 466/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7351 - val_loss: 0.5513 - val_accuracy: 0.7391\n",
            "Epoch 467/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7346 - val_loss: 0.5503 - val_accuracy: 0.7357\n",
            "Epoch 468/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7341 - val_loss: 0.5516 - val_accuracy: 0.7380\n",
            "Epoch 469/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7358 - val_loss: 0.5506 - val_accuracy: 0.7383\n",
            "Epoch 470/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5526 - val_accuracy: 0.7375\n",
            "Epoch 471/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7350 - val_loss: 0.5517 - val_accuracy: 0.7370\n",
            "Epoch 472/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7347 - val_loss: 0.5515 - val_accuracy: 0.7370\n",
            "Epoch 473/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5488 - val_accuracy: 0.7365\n",
            "Epoch 474/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7353 - val_loss: 0.5505 - val_accuracy: 0.7380\n",
            "Epoch 475/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7345 - val_loss: 0.5570 - val_accuracy: 0.7372\n",
            "Epoch 476/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7352 - val_loss: 0.5550 - val_accuracy: 0.7367\n",
            "Epoch 477/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7342 - val_loss: 0.5558 - val_accuracy: 0.7354\n",
            "Epoch 478/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7344 - val_loss: 0.5525 - val_accuracy: 0.7378\n",
            "Epoch 479/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7348 - val_loss: 0.5533 - val_accuracy: 0.7352\n",
            "Epoch 480/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7347 - val_loss: 0.5538 - val_accuracy: 0.7378\n",
            "Epoch 481/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7356 - val_loss: 0.5588 - val_accuracy: 0.7370\n",
            "Epoch 482/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7353 - val_loss: 0.5517 - val_accuracy: 0.7354\n",
            "Epoch 483/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7352 - val_loss: 0.5521 - val_accuracy: 0.7352\n",
            "Epoch 484/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5562 - val_accuracy: 0.7339\n",
            "Epoch 485/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7347 - val_loss: 0.5519 - val_accuracy: 0.7385\n",
            "Epoch 486/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7351 - val_loss: 0.5524 - val_accuracy: 0.7354\n",
            "Epoch 487/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7356 - val_loss: 0.5553 - val_accuracy: 0.7365\n",
            "Epoch 488/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7347 - val_loss: 0.5530 - val_accuracy: 0.7365\n",
            "Epoch 489/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7354 - val_loss: 0.5529 - val_accuracy: 0.7372\n",
            "Epoch 490/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7340 - val_loss: 0.5510 - val_accuracy: 0.7383\n",
            "Epoch 491/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7351 - val_loss: 0.5513 - val_accuracy: 0.7375\n",
            "Epoch 492/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7348 - val_loss: 0.5527 - val_accuracy: 0.7378\n",
            "Epoch 493/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7361 - val_loss: 0.5582 - val_accuracy: 0.7367\n",
            "Epoch 494/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5538 - val_accuracy: 0.7362\n",
            "Epoch 495/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7348 - val_loss: 0.5528 - val_accuracy: 0.7367\n",
            "Epoch 496/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7355 - val_loss: 0.5547 - val_accuracy: 0.7367\n",
            "Epoch 497/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7350 - val_loss: 0.5521 - val_accuracy: 0.7372\n",
            "Epoch 498/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7349 - val_loss: 0.5516 - val_accuracy: 0.7367\n",
            "Epoch 499/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7352 - val_loss: 0.5512 - val_accuracy: 0.7372\n",
            "Epoch 500/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7355 - val_loss: 0.5569 - val_accuracy: 0.7367\n",
            "Epoch 501/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7359 - val_loss: 0.5543 - val_accuracy: 0.7370\n",
            "Epoch 502/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7359 - val_loss: 0.5572 - val_accuracy: 0.7346\n",
            "Epoch 503/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7349 - val_loss: 0.5567 - val_accuracy: 0.7362\n",
            "Epoch 504/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7355 - val_loss: 0.5545 - val_accuracy: 0.7378\n",
            "Epoch 505/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7352 - val_loss: 0.5548 - val_accuracy: 0.7388\n",
            "Epoch 506/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7349 - val_loss: 0.5527 - val_accuracy: 0.7367\n",
            "Epoch 507/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7345 - val_loss: 0.5566 - val_accuracy: 0.7375\n",
            "Epoch 508/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7353 - val_loss: 0.5524 - val_accuracy: 0.7365\n",
            "Epoch 509/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7353 - val_loss: 0.5565 - val_accuracy: 0.7372\n",
            "Epoch 510/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7350 - val_loss: 0.5511 - val_accuracy: 0.7367\n",
            "Epoch 511/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7360 - val_loss: 0.5551 - val_accuracy: 0.7372\n",
            "Epoch 512/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7349 - val_loss: 0.5529 - val_accuracy: 0.7383\n",
            "Epoch 513/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7346 - val_loss: 0.5520 - val_accuracy: 0.7388\n",
            "Epoch 514/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7361 - val_loss: 0.5550 - val_accuracy: 0.7385\n",
            "Epoch 515/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7350 - val_loss: 0.5534 - val_accuracy: 0.7375\n",
            "Epoch 516/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7356 - val_loss: 0.5524 - val_accuracy: 0.7370\n",
            "Epoch 517/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7352 - val_loss: 0.5553 - val_accuracy: 0.7378\n",
            "Epoch 518/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7350 - val_loss: 0.5544 - val_accuracy: 0.7375\n",
            "Epoch 519/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7348 - val_loss: 0.5523 - val_accuracy: 0.7388\n",
            "Epoch 520/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7347 - val_loss: 0.5538 - val_accuracy: 0.7385\n",
            "Epoch 521/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7344 - val_loss: 0.5533 - val_accuracy: 0.7375\n",
            "Epoch 522/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7346 - val_loss: 0.5536 - val_accuracy: 0.7365\n",
            "Epoch 523/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7355 - val_loss: 0.5539 - val_accuracy: 0.7372\n",
            "Epoch 524/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7353 - val_loss: 0.5537 - val_accuracy: 0.7367\n",
            "Epoch 525/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7355 - val_loss: 0.5518 - val_accuracy: 0.7378\n",
            "Epoch 526/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7358 - val_loss: 0.5582 - val_accuracy: 0.7365\n",
            "Epoch 527/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7359 - val_loss: 0.5540 - val_accuracy: 0.7362\n",
            "Epoch 528/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7349 - val_loss: 0.5535 - val_accuracy: 0.7362\n",
            "Epoch 529/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5515 - val_accuracy: 0.7370\n",
            "Epoch 530/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7358 - val_loss: 0.5517 - val_accuracy: 0.7385\n",
            "Epoch 531/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7353 - val_loss: 0.5527 - val_accuracy: 0.7370\n",
            "Epoch 532/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7343 - val_loss: 0.5517 - val_accuracy: 0.7370\n",
            "Epoch 533/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7354 - val_loss: 0.5523 - val_accuracy: 0.7370\n",
            "Epoch 534/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7357 - val_loss: 0.5561 - val_accuracy: 0.7370\n",
            "Epoch 535/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7349 - val_loss: 0.5523 - val_accuracy: 0.7385\n",
            "Epoch 536/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5523 - val_accuracy: 0.7375\n",
            "Epoch 537/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7358 - val_loss: 0.5523 - val_accuracy: 0.7378\n",
            "Epoch 538/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7346 - val_loss: 0.5509 - val_accuracy: 0.7385\n",
            "Epoch 539/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7358 - val_loss: 0.5535 - val_accuracy: 0.7367\n",
            "Epoch 540/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7362 - val_loss: 0.5536 - val_accuracy: 0.7380\n",
            "Epoch 541/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7350 - val_loss: 0.5528 - val_accuracy: 0.7380\n",
            "Epoch 542/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7355 - val_loss: 0.5540 - val_accuracy: 0.7380\n",
            "Epoch 543/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7353 - val_loss: 0.5503 - val_accuracy: 0.7372\n",
            "Epoch 544/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7349 - val_loss: 0.5525 - val_accuracy: 0.7370\n",
            "Epoch 545/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7351 - val_loss: 0.5538 - val_accuracy: 0.7375\n",
            "Epoch 546/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7355 - val_loss: 0.5613 - val_accuracy: 0.7378\n",
            "Epoch 547/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7340 - val_loss: 0.5511 - val_accuracy: 0.7372\n",
            "Epoch 548/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7358 - val_loss: 0.5566 - val_accuracy: 0.7346\n",
            "Epoch 549/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7356 - val_loss: 0.5558 - val_accuracy: 0.7357\n",
            "Epoch 550/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7352 - val_loss: 0.5510 - val_accuracy: 0.7357\n",
            "Epoch 551/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7344 - val_loss: 0.5553 - val_accuracy: 0.7370\n",
            "Epoch 552/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7350 - val_loss: 0.5522 - val_accuracy: 0.7370\n",
            "Epoch 553/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7354 - val_loss: 0.5535 - val_accuracy: 0.7380\n",
            "Epoch 554/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7357 - val_loss: 0.5533 - val_accuracy: 0.7375\n",
            "Epoch 555/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7341 - val_loss: 0.5557 - val_accuracy: 0.7372\n",
            "Epoch 556/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7365 - val_loss: 0.5537 - val_accuracy: 0.7359\n",
            "Epoch 557/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5530 - val_accuracy: 0.7372\n",
            "Epoch 558/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7358 - val_loss: 0.5541 - val_accuracy: 0.7359\n",
            "Epoch 559/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7344 - val_loss: 0.5576 - val_accuracy: 0.7370\n",
            "Epoch 560/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7362 - val_loss: 0.5523 - val_accuracy: 0.7362\n",
            "Epoch 561/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7352 - val_loss: 0.5523 - val_accuracy: 0.7375\n",
            "Epoch 562/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7358 - val_loss: 0.5516 - val_accuracy: 0.7372\n",
            "Epoch 563/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7361 - val_loss: 0.5526 - val_accuracy: 0.7367\n",
            "Epoch 564/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7363 - val_loss: 0.5530 - val_accuracy: 0.7375\n",
            "Epoch 565/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7356 - val_loss: 0.5544 - val_accuracy: 0.7372\n",
            "Epoch 566/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5533 - val_accuracy: 0.7354\n",
            "Epoch 567/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7364 - val_loss: 0.5529 - val_accuracy: 0.7378\n",
            "Epoch 568/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7348 - val_loss: 0.5541 - val_accuracy: 0.7388\n",
            "Epoch 569/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7354 - val_loss: 0.5553 - val_accuracy: 0.7354\n",
            "Epoch 570/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7357 - val_loss: 0.5542 - val_accuracy: 0.7372\n",
            "Epoch 571/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7353 - val_loss: 0.5522 - val_accuracy: 0.7370\n",
            "Epoch 572/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7357 - val_loss: 0.5532 - val_accuracy: 0.7357\n",
            "Epoch 573/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7362 - val_loss: 0.5528 - val_accuracy: 0.7380\n",
            "Epoch 574/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7355 - val_loss: 0.5543 - val_accuracy: 0.7365\n",
            "Epoch 575/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7363 - val_loss: 0.5515 - val_accuracy: 0.7380\n",
            "Epoch 576/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7358 - val_loss: 0.5537 - val_accuracy: 0.7372\n",
            "Epoch 577/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7350 - val_loss: 0.5524 - val_accuracy: 0.7388\n",
            "Epoch 578/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7358 - val_loss: 0.5521 - val_accuracy: 0.7378\n",
            "Epoch 579/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7352 - val_loss: 0.5529 - val_accuracy: 0.7370\n",
            "Epoch 580/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7355 - val_loss: 0.5521 - val_accuracy: 0.7380\n",
            "Epoch 581/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7355 - val_loss: 0.5553 - val_accuracy: 0.7362\n",
            "Epoch 582/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7355 - val_loss: 0.5552 - val_accuracy: 0.7370\n",
            "Epoch 583/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7354 - val_loss: 0.5558 - val_accuracy: 0.7370\n",
            "Epoch 584/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7359 - val_loss: 0.5531 - val_accuracy: 0.7380\n",
            "Epoch 585/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7356 - val_loss: 0.5538 - val_accuracy: 0.7383\n",
            "Epoch 586/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7350 - val_loss: 0.5553 - val_accuracy: 0.7380\n",
            "Epoch 587/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7347 - val_loss: 0.5570 - val_accuracy: 0.7346\n",
            "Epoch 588/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7350 - val_loss: 0.5537 - val_accuracy: 0.7362\n",
            "Epoch 589/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7358 - val_loss: 0.5510 - val_accuracy: 0.7370\n",
            "Epoch 590/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7356 - val_loss: 0.5521 - val_accuracy: 0.7367\n",
            "Epoch 591/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7356 - val_loss: 0.5531 - val_accuracy: 0.7372\n",
            "Epoch 592/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7350 - val_loss: 0.5519 - val_accuracy: 0.7375\n",
            "Epoch 593/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7358 - val_loss: 0.5527 - val_accuracy: 0.7372\n",
            "Epoch 594/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7357 - val_loss: 0.5542 - val_accuracy: 0.7365\n",
            "Epoch 595/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7363 - val_loss: 0.5543 - val_accuracy: 0.7362\n",
            "Epoch 596/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7348 - val_loss: 0.5508 - val_accuracy: 0.7365\n",
            "Epoch 597/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7359 - val_loss: 0.5554 - val_accuracy: 0.7367\n",
            "Epoch 598/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7352 - val_loss: 0.5551 - val_accuracy: 0.7359\n",
            "Epoch 599/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7355 - val_loss: 0.5533 - val_accuracy: 0.7375\n",
            "Epoch 600/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7359 - val_loss: 0.5509 - val_accuracy: 0.7380\n",
            "Epoch 601/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7357 - val_loss: 0.5520 - val_accuracy: 0.7380\n",
            "Epoch 602/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7357 - val_loss: 0.5513 - val_accuracy: 0.7378\n",
            "Epoch 603/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7362 - val_loss: 0.5539 - val_accuracy: 0.7365\n",
            "Epoch 604/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7349 - val_loss: 0.5543 - val_accuracy: 0.7349\n",
            "Epoch 605/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7353 - val_loss: 0.5523 - val_accuracy: 0.7370\n",
            "Epoch 606/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7359 - val_loss: 0.5532 - val_accuracy: 0.7367\n",
            "Epoch 607/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7355 - val_loss: 0.5525 - val_accuracy: 0.7362\n",
            "Epoch 608/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7352 - val_loss: 0.5513 - val_accuracy: 0.7365\n",
            "Epoch 609/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7351 - val_loss: 0.5530 - val_accuracy: 0.7378\n",
            "Epoch 610/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7362 - val_loss: 0.5543 - val_accuracy: 0.7375\n",
            "Epoch 611/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7355 - val_loss: 0.5533 - val_accuracy: 0.7372\n",
            "Epoch 612/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7362 - val_loss: 0.5574 - val_accuracy: 0.7359\n",
            "Epoch 613/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5528 - val_accuracy: 0.7372\n",
            "Epoch 614/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7349 - val_loss: 0.5541 - val_accuracy: 0.7378\n",
            "Epoch 615/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7351 - val_loss: 0.5522 - val_accuracy: 0.7375\n",
            "Epoch 616/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7354 - val_loss: 0.5550 - val_accuracy: 0.7367\n",
            "Epoch 617/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5515 - val_accuracy: 0.7375\n",
            "Epoch 618/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7360 - val_loss: 0.5564 - val_accuracy: 0.7357\n",
            "Epoch 619/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7357 - val_loss: 0.5498 - val_accuracy: 0.7362\n",
            "Epoch 620/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5524 - val_accuracy: 0.7362\n",
            "Epoch 621/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5540 - val_accuracy: 0.7339\n",
            "Epoch 622/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7350 - val_loss: 0.5530 - val_accuracy: 0.7359\n",
            "Epoch 623/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7352 - val_loss: 0.5535 - val_accuracy: 0.7362\n",
            "Epoch 624/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7356 - val_loss: 0.5513 - val_accuracy: 0.7383\n",
            "Epoch 625/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7350 - val_loss: 0.5529 - val_accuracy: 0.7372\n",
            "Epoch 626/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7368 - val_loss: 0.5526 - val_accuracy: 0.7349\n",
            "Epoch 627/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7354 - val_loss: 0.5513 - val_accuracy: 0.7380\n",
            "Epoch 628/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7357 - val_loss: 0.5511 - val_accuracy: 0.7367\n",
            "Epoch 629/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7356 - val_loss: 0.5524 - val_accuracy: 0.7362\n",
            "Epoch 630/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7346 - val_loss: 0.5505 - val_accuracy: 0.7375\n",
            "Epoch 631/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7352 - val_loss: 0.5517 - val_accuracy: 0.7370\n",
            "Epoch 632/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7355 - val_loss: 0.5528 - val_accuracy: 0.7370\n",
            "Epoch 633/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7346 - val_loss: 0.5528 - val_accuracy: 0.7372\n",
            "Epoch 634/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7348 - val_loss: 0.5527 - val_accuracy: 0.7370\n",
            "Epoch 635/780\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5559 - val_accuracy: 0.7372\n",
            "Epoch 636/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7350 - val_loss: 0.5556 - val_accuracy: 0.7365\n",
            "Epoch 637/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7356 - val_loss: 0.5544 - val_accuracy: 0.7378\n",
            "Epoch 638/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7361 - val_loss: 0.5553 - val_accuracy: 0.7354\n",
            "Epoch 639/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7362 - val_loss: 0.5546 - val_accuracy: 0.7370\n",
            "Epoch 640/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7351 - val_loss: 0.5529 - val_accuracy: 0.7370\n",
            "Epoch 641/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7359 - val_loss: 0.5519 - val_accuracy: 0.7383\n",
            "Epoch 642/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7362 - val_loss: 0.5558 - val_accuracy: 0.7354\n",
            "Epoch 643/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7361 - val_loss: 0.5524 - val_accuracy: 0.7375\n",
            "Epoch 644/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7363 - val_loss: 0.5521 - val_accuracy: 0.7375\n",
            "Epoch 645/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7354 - val_loss: 0.5543 - val_accuracy: 0.7359\n",
            "Epoch 646/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7351 - val_loss: 0.5524 - val_accuracy: 0.7357\n",
            "Epoch 647/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7351 - val_loss: 0.5527 - val_accuracy: 0.7372\n",
            "Epoch 648/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5542 - val_accuracy: 0.7370\n",
            "Epoch 649/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7356 - val_loss: 0.5517 - val_accuracy: 0.7380\n",
            "Epoch 650/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7355 - val_loss: 0.5580 - val_accuracy: 0.7334\n",
            "Epoch 651/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7354 - val_loss: 0.5544 - val_accuracy: 0.7367\n",
            "Epoch 652/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7362 - val_loss: 0.5512 - val_accuracy: 0.7367\n",
            "Epoch 653/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7360 - val_loss: 0.5524 - val_accuracy: 0.7367\n",
            "Epoch 654/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7354 - val_loss: 0.5510 - val_accuracy: 0.7375\n",
            "Epoch 655/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7357 - val_loss: 0.5554 - val_accuracy: 0.7365\n",
            "Epoch 656/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7367 - val_loss: 0.5513 - val_accuracy: 0.7372\n",
            "Epoch 657/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7349 - val_loss: 0.5543 - val_accuracy: 0.7370\n",
            "Epoch 658/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7355 - val_loss: 0.5545 - val_accuracy: 0.7367\n",
            "Epoch 659/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7354 - val_loss: 0.5530 - val_accuracy: 0.7365\n",
            "Epoch 660/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7360 - val_loss: 0.5537 - val_accuracy: 0.7372\n",
            "Epoch 661/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7356 - val_loss: 0.5556 - val_accuracy: 0.7359\n",
            "Epoch 662/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5525 - val_accuracy: 0.7362\n",
            "Epoch 663/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7358 - val_loss: 0.5544 - val_accuracy: 0.7365\n",
            "Epoch 664/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7353 - val_loss: 0.5561 - val_accuracy: 0.7352\n",
            "Epoch 665/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7361 - val_loss: 0.5530 - val_accuracy: 0.7357\n",
            "Epoch 666/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7356 - val_loss: 0.5526 - val_accuracy: 0.7380\n",
            "Epoch 667/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7358 - val_loss: 0.5567 - val_accuracy: 0.7370\n",
            "Epoch 668/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7366 - val_loss: 0.5546 - val_accuracy: 0.7365\n",
            "Epoch 669/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7356 - val_loss: 0.5543 - val_accuracy: 0.7375\n",
            "Epoch 670/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7364 - val_loss: 0.5530 - val_accuracy: 0.7380\n",
            "Epoch 671/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7360 - val_loss: 0.5530 - val_accuracy: 0.7375\n",
            "Epoch 672/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7358 - val_loss: 0.5544 - val_accuracy: 0.7378\n",
            "Epoch 673/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7358 - val_loss: 0.5528 - val_accuracy: 0.7370\n",
            "Epoch 674/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7353 - val_loss: 0.5539 - val_accuracy: 0.7378\n",
            "Epoch 675/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7351 - val_loss: 0.5537 - val_accuracy: 0.7375\n",
            "Epoch 676/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7356 - val_loss: 0.5556 - val_accuracy: 0.7375\n",
            "Epoch 677/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7356 - val_loss: 0.5554 - val_accuracy: 0.7362\n",
            "Epoch 678/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7354 - val_loss: 0.5537 - val_accuracy: 0.7362\n",
            "Epoch 679/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7358 - val_loss: 0.5527 - val_accuracy: 0.7367\n",
            "Epoch 680/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7355 - val_loss: 0.5545 - val_accuracy: 0.7357\n",
            "Epoch 681/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7358 - val_loss: 0.5536 - val_accuracy: 0.7372\n",
            "Epoch 682/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7355 - val_loss: 0.5539 - val_accuracy: 0.7370\n",
            "Epoch 683/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7364 - val_loss: 0.5545 - val_accuracy: 0.7362\n",
            "Epoch 684/780\n",
            "684/684 [==============================] - 2s 4ms/step - loss: 0.5422 - accuracy: 0.7363 - val_loss: 0.5511 - val_accuracy: 0.7365\n",
            "Epoch 685/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7362 - val_loss: 0.5521 - val_accuracy: 0.7378\n",
            "Epoch 686/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7359 - val_loss: 0.5523 - val_accuracy: 0.7383\n",
            "Epoch 687/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5549 - val_accuracy: 0.7365\n",
            "Epoch 688/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7360 - val_loss: 0.5531 - val_accuracy: 0.7359\n",
            "Epoch 689/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7354 - val_loss: 0.5546 - val_accuracy: 0.7362\n",
            "Epoch 690/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5546 - val_accuracy: 0.7367\n",
            "Epoch 691/780\n",
            "684/684 [==============================] - 2s 4ms/step - loss: 0.5421 - accuracy: 0.7357 - val_loss: 0.5544 - val_accuracy: 0.7367\n",
            "Epoch 692/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7356 - val_loss: 0.5551 - val_accuracy: 0.7359\n",
            "Epoch 693/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7345 - val_loss: 0.5537 - val_accuracy: 0.7362\n",
            "Epoch 694/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7351 - val_loss: 0.5588 - val_accuracy: 0.7349\n",
            "Epoch 695/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5539 - val_accuracy: 0.7372\n",
            "Epoch 696/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7356 - val_loss: 0.5519 - val_accuracy: 0.7375\n",
            "Epoch 697/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5533 - val_accuracy: 0.7370\n",
            "Epoch 698/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7361 - val_loss: 0.5544 - val_accuracy: 0.7367\n",
            "Epoch 699/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7362 - val_loss: 0.5565 - val_accuracy: 0.7375\n",
            "Epoch 700/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7359 - val_loss: 0.5546 - val_accuracy: 0.7372\n",
            "Epoch 701/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7352 - val_loss: 0.5521 - val_accuracy: 0.7380\n",
            "Epoch 702/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7359 - val_loss: 0.5526 - val_accuracy: 0.7365\n",
            "Epoch 703/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7351 - val_loss: 0.5528 - val_accuracy: 0.7365\n",
            "Epoch 704/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7360 - val_loss: 0.5527 - val_accuracy: 0.7378\n",
            "Epoch 705/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7354 - val_loss: 0.5515 - val_accuracy: 0.7378\n",
            "Epoch 706/780\n",
            "684/684 [==============================] - 2s 4ms/step - loss: 0.5416 - accuracy: 0.7348 - val_loss: 0.5601 - val_accuracy: 0.7339\n",
            "Epoch 707/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7357 - val_loss: 0.5536 - val_accuracy: 0.7372\n",
            "Epoch 708/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7359 - val_loss: 0.5538 - val_accuracy: 0.7372\n",
            "Epoch 709/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7361 - val_loss: 0.5525 - val_accuracy: 0.7378\n",
            "Epoch 710/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7359 - val_loss: 0.5532 - val_accuracy: 0.7375\n",
            "Epoch 711/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7361 - val_loss: 0.5539 - val_accuracy: 0.7367\n",
            "Epoch 712/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7349 - val_loss: 0.5623 - val_accuracy: 0.7365\n",
            "Epoch 713/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7358 - val_loss: 0.5546 - val_accuracy: 0.7365\n",
            "Epoch 714/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7365 - val_loss: 0.5537 - val_accuracy: 0.7372\n",
            "Epoch 715/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7360 - val_loss: 0.5531 - val_accuracy: 0.7365\n",
            "Epoch 716/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7359 - val_loss: 0.5537 - val_accuracy: 0.7357\n",
            "Epoch 717/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7351 - val_loss: 0.5535 - val_accuracy: 0.7362\n",
            "Epoch 718/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7353 - val_loss: 0.5525 - val_accuracy: 0.7352\n",
            "Epoch 719/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7357 - val_loss: 0.5576 - val_accuracy: 0.7346\n",
            "Epoch 720/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7352 - val_loss: 0.5507 - val_accuracy: 0.7375\n",
            "Epoch 721/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7357 - val_loss: 0.5539 - val_accuracy: 0.7367\n",
            "Epoch 722/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7363 - val_loss: 0.5539 - val_accuracy: 0.7370\n",
            "Epoch 723/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5536 - val_accuracy: 0.7375\n",
            "Epoch 724/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7360 - val_loss: 0.5534 - val_accuracy: 0.7370\n",
            "Epoch 725/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5534 - val_accuracy: 0.7372\n",
            "Epoch 726/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7362 - val_loss: 0.5535 - val_accuracy: 0.7357\n",
            "Epoch 727/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7348 - val_loss: 0.5545 - val_accuracy: 0.7365\n",
            "Epoch 728/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7365 - val_loss: 0.5540 - val_accuracy: 0.7375\n",
            "Epoch 729/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7358 - val_loss: 0.5543 - val_accuracy: 0.7370\n",
            "Epoch 730/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7355 - val_loss: 0.5534 - val_accuracy: 0.7359\n",
            "Epoch 731/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5545 - val_accuracy: 0.7380\n",
            "Epoch 732/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7356 - val_loss: 0.5558 - val_accuracy: 0.7370\n",
            "Epoch 733/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7366 - val_loss: 0.5559 - val_accuracy: 0.7378\n",
            "Epoch 734/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7361 - val_loss: 0.5565 - val_accuracy: 0.7370\n",
            "Epoch 735/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7367 - val_loss: 0.5537 - val_accuracy: 0.7375\n",
            "Epoch 736/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7360 - val_loss: 0.5536 - val_accuracy: 0.7378\n",
            "Epoch 737/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7363 - val_loss: 0.5525 - val_accuracy: 0.7385\n",
            "Epoch 738/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5540 - val_accuracy: 0.7367\n",
            "Epoch 739/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7354 - val_loss: 0.5507 - val_accuracy: 0.7375\n",
            "Epoch 740/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7359 - val_loss: 0.5530 - val_accuracy: 0.7378\n",
            "Epoch 741/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7352 - val_loss: 0.5525 - val_accuracy: 0.7370\n",
            "Epoch 742/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7352 - val_loss: 0.5552 - val_accuracy: 0.7365\n",
            "Epoch 743/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5415 - accuracy: 0.7369 - val_loss: 0.5560 - val_accuracy: 0.7372\n",
            "Epoch 744/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7353 - val_loss: 0.5570 - val_accuracy: 0.7359\n",
            "Epoch 745/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7360 - val_loss: 0.5526 - val_accuracy: 0.7365\n",
            "Epoch 746/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7352 - val_loss: 0.5547 - val_accuracy: 0.7365\n",
            "Epoch 747/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7366 - val_loss: 0.5586 - val_accuracy: 0.7349\n",
            "Epoch 748/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7353 - val_loss: 0.5603 - val_accuracy: 0.7372\n",
            "Epoch 749/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7362 - val_loss: 0.5523 - val_accuracy: 0.7367\n",
            "Epoch 750/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7359 - val_loss: 0.5567 - val_accuracy: 0.7334\n",
            "Epoch 751/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7359 - val_loss: 0.5531 - val_accuracy: 0.7375\n",
            "Epoch 752/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7367 - val_loss: 0.5521 - val_accuracy: 0.7383\n",
            "Epoch 753/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7358 - val_loss: 0.5584 - val_accuracy: 0.7362\n",
            "Epoch 754/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7362 - val_loss: 0.5551 - val_accuracy: 0.7372\n",
            "Epoch 755/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7355 - val_loss: 0.5536 - val_accuracy: 0.7365\n",
            "Epoch 756/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7367 - val_loss: 0.5561 - val_accuracy: 0.7359\n",
            "Epoch 757/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7365 - val_loss: 0.5559 - val_accuracy: 0.7370\n",
            "Epoch 758/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7357 - val_loss: 0.5560 - val_accuracy: 0.7388\n",
            "Epoch 759/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7360 - val_loss: 0.5545 - val_accuracy: 0.7378\n",
            "Epoch 760/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7364 - val_loss: 0.5537 - val_accuracy: 0.7393\n",
            "Epoch 761/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7363 - val_loss: 0.5549 - val_accuracy: 0.7375\n",
            "Epoch 762/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7354 - val_loss: 0.5553 - val_accuracy: 0.7375\n",
            "Epoch 763/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5558 - val_accuracy: 0.7370\n",
            "Epoch 764/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7357 - val_loss: 0.5555 - val_accuracy: 0.7367\n",
            "Epoch 765/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7366 - val_loss: 0.5666 - val_accuracy: 0.7383\n",
            "Epoch 766/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7367 - val_loss: 0.5558 - val_accuracy: 0.7357\n",
            "Epoch 767/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7358 - val_loss: 0.5588 - val_accuracy: 0.7354\n",
            "Epoch 768/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7350 - val_loss: 0.5556 - val_accuracy: 0.7365\n",
            "Epoch 769/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7362 - val_loss: 0.5535 - val_accuracy: 0.7359\n",
            "Epoch 770/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7351 - val_loss: 0.5546 - val_accuracy: 0.7370\n",
            "Epoch 771/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5415 - accuracy: 0.7357 - val_loss: 0.5539 - val_accuracy: 0.7372\n",
            "Epoch 772/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7360 - val_loss: 0.5574 - val_accuracy: 0.7341\n",
            "Epoch 773/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7356 - val_loss: 0.5542 - val_accuracy: 0.7370\n",
            "Epoch 774/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7360 - val_loss: 0.5570 - val_accuracy: 0.7365\n",
            "Epoch 775/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7361 - val_loss: 0.5559 - val_accuracy: 0.7362\n",
            "Epoch 776/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7356 - val_loss: 0.5567 - val_accuracy: 0.7372\n",
            "Epoch 777/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7353 - val_loss: 0.5585 - val_accuracy: 0.7362\n",
            "Epoch 778/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7358 - val_loss: 0.5582 - val_accuracy: 0.7357\n",
            "Epoch 779/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7363 - val_loss: 0.5540 - val_accuracy: 0.7372\n",
            "Epoch 780/780\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7360 - val_loss: 0.5583 - val_accuracy: 0.7352\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,validation_split=0.15, epochs=780)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQgtL2vQtHrK",
        "outputId": "d07d80c4-27a0-4a8b-cfe6-9ea53716415b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5613 - accuracy: 0.7345 - 369ms/epoch - 1ms/step\n",
            "Loss: 0.5613431930541992, Accuracy: 0.7344606518745422\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "PZOtbWG0tHmZ",
        "outputId": "5d46010f-3bb3-4a4f-a191-28056db09f9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "# .h5 files are considered legacy and the library suggested to save it as .keras, saved both formats.\n",
        "nn.save(\"./modelHDF5_2.h5\")\n",
        "nn.save(\"./modelKERAS_2.keras\")\n",
        "plot_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
        "plot_df.plot(y = 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbCWQm1L5cND"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
